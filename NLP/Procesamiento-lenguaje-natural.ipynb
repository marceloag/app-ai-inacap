{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Procesamiento de Lenguaje Natural con LLMs\n",
        "### Modelo ClÃ¡sico a Modelos Modernos ğŸš€\n",
        "\n",
        "Este notebook muestra la evoluciÃ³n del NLP:\n",
        "1. Fundamentos clÃ¡sicos (preprocesamiento y representaciÃ³n)\n",
        "2. ClasificaciÃ³n tradicional\n",
        "3. LLMs modernos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARTE 1: FUNDAMENTOS CLÃSICOS DE NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install nltk transformers torch scikit-learn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "from collections import Counter\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset simple para clasificaciÃ³n de sentimientos\n",
        "reviews = [\n",
        "    \"Me encanta este producto, es increÃ­ble!\",\n",
        "    \"PÃ©sima experiencia, no lo recomiendo\",\n",
        "    \"Es aceptable, cumple lo esperado\",\n",
        "    \"Excelente compra, superÃ³ expectativas\",\n",
        "    \"Horrible servicio, muy decepcionado\"\n",
        "]\n",
        "sentimientos = ['positivo', 'negativo', 'neutral', 'positivo', 'negativo']\n",
        "\n",
        "print(\"=== DATASET ORIGINAL ===\")\n",
        "for i, (review, sent) in enumerate(zip(reviews, sentimientos), 1):\n",
        "    print(f\"{i}. [{sent}] {review}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocesamiento ClÃ¡sico\n",
        "\n",
        "**PREPROCESAMIENTO**: Limpiar y normalizar texto para anÃ¡lisis.\n",
        "- TokenizaciÃ³n: dividir en palabras\n",
        "- Stop words: remover palabras comunes sin significado\n",
        "- Stemming: reducir palabras a su raÃ­z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "stemmer = SnowballStemmer('spanish')\n",
        "\n",
        "def preprocesar(texto):\n",
        "    # Limpiar y tokenizar\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto.lower())\n",
        "    tokens = word_tokenize(texto)\n",
        "    # Remover stop words y hacer stemming\n",
        "    tokens = [stemmer.stem(t) for t in tokens if t not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "reviews_procesados = [preprocesar(r) for r in reviews]\n",
        "\n",
        "print(\"\\n=== DESPUÃ‰S DEL PREPROCESAMIENTO ===\")\n",
        "for i, review in enumerate(reviews_procesados, 1):\n",
        "    print(f\"{i}. {review}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RepresentaciÃ³n: Bag of Words\n",
        "\n",
        "**BAG OF WORDS**: Representa texto como vector de frecuencias de palabras.\n",
        "Cada palabra del vocabulario es una dimensiÃ³n.\n",
        "Problema: Pierde contexto y semÃ¡ntica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(reviews_procesados)\n",
        "\n",
        "print(\"\\n=== BAG OF WORDS (TF-IDF) ===\")\n",
        "print(f\"Vocabulario: {vectorizer.get_feature_names_out()}\")\n",
        "print(f\"DimensiÃ³n: {X.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ClasificaciÃ³n Tradicional\n",
        "\n",
        "**CLASIFICACIÃ“N CLÃSICA**: Usamos algoritmos como Naive Bayes o SVM.\n",
        "Requieren mucho preprocesamiento y features engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "clf = MultinomialNB()\n",
        "scores = cross_val_score(clf, X, sentimientos, cv=2)\n",
        "print(f\"\\n=== CLASIFICACIÃ“N TRADICIONAL (Naive Bayes) ===\")\n",
        "print(f\"Accuracy promedio: {scores.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARTE 2: Â¡LA REVOLUCIÃ“N DE LOS LLMs! ğŸ¤–âœ¨\n",
        "\n",
        "**LLMs (Large Language Models)**: Modelos masivos entrenados en billones de palabras.\n",
        "- Entienden contexto, semÃ¡ntica y relaciones complejas\n",
        "- No necesitan preprocesamiento manual\n",
        "- Pueden hacer mÃºltiples tareas sin reentrenamiento (zero-shot)\n",
        "- Ejemplos: BERT, GPT, LLaMA, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸš€ CARGANDO MODELO DE LENGUAJE MODERNO...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Cargamos un modelo preentrenado en espaÃ±ol para anÃ¡lisis de sentimientos\n",
        "# Este modelo ya fue entrenado en millones de textos\n",
        "clasificador_llm = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"pysentimiento/robertuito-sentiment-analysis\"\n",
        ")\n",
        "\n",
        "print(\"âœ… Modelo cargado: RoBERTuito (BERT en espaÃ±ol)\")\n",
        "print(\"   Entrenado en millones de tweets en espaÃ±ol\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AnÃ¡lisis con LLM - Zero Shot\n",
        "\n",
        "**ZERO-SHOT**: El modelo puede clasificar SIN ver ejemplos de entrenamiento.\n",
        "Ya aprendiÃ³ sobre sentimientos de su entrenamiento masivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== CLASIFICACIÃ“N CON LLM (Sin preprocesamiento) ===\\n\")\n",
        "\n",
        "for i, review in enumerate(reviews, 1):\n",
        "    resultado = clasificador_llm(review)[0]\n",
        "    etiqueta = resultado['label']\n",
        "    confianza = resultado['score']\n",
        "    \n",
        "    # Mapeo de etiquetas\n",
        "    etiqueta_es = {'POS': 'ğŸ˜Š Positivo', 'NEG': 'ğŸ˜ Negativo', 'NEU': 'ğŸ˜ Neutral'}\n",
        "    \n",
        "    print(f\"{i}. \\\"{review}\\\"\")\n",
        "    print(f\"   PredicciÃ³n: {etiqueta_es.get(etiqueta, etiqueta)} (confianza: {confianza:.2%})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Casos mÃ¡s complejos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ§ª PROBANDO CON CASOS DESAFIANTES\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "casos_complejos = [\n",
        "    \"No es que sea malo, pero definitivamente no es bueno\",  # NegaciÃ³n compleja\n",
        "    \"Esperaba mÃ¡s, aunque tiene sus puntos positivos\",       # Sentimiento mixto\n",
        "    \"Â¡QuÃ© desastre tan espectacular! (Es ironÃ­a)\",          # IronÃ­a\n",
        "    \"IncreÃ­ble cÃ³mo algo tan caro puede ser tan mediocre\"   # Sarcasmo\n",
        "]\n",
        "\n",
        "for caso in casos_complejos:\n",
        "    resultado = clasificador_llm(caso)[0]\n",
        "    etiqueta = {'POS': 'ğŸ˜Š', 'NEG': 'ğŸ˜', 'NEU': 'ğŸ˜'}.get(resultado['label'], 'ğŸ¤”')\n",
        "    \n",
        "    print(f\"ğŸ“ \\\"{caso}\\\"\")\n",
        "    print(f\"   {etiqueta} {resultado['label']} ({resultado['score']:.1%})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARTE 3: GENERACIÃ“N DE TEXTO CON LLMs ğŸ¨\n",
        "\n",
        "Los LLMs tambiÃ©n pueden **GENERAR** texto coherente.\n",
        "Vamos a usar un modelo generativo en espaÃ±ol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ¨ GENERACIÃ“N DE TEXTO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Modelo generativo (mÃ¡s pequeÃ±o para Google Colab)\n",
        "generador = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"DeepESP/gpt2-spanish\",\n",
        "    max_length=80\n",
        ")\n",
        "\n",
        "prompts = [\n",
        "    \"La inteligencia artificial es\",\n",
        "    \"En el futuro, los robots\",\n",
        "    \"El curso de IA me parece\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    texto_generado = generador(prompt, do_sample=True, temperature=0.7)[0]['generated_text']\n",
        "    print(f\"ğŸ’­ Prompt: \\\"{prompt}\\\"\")\n",
        "    print(f\"âœ¨ Generado: {texto_generado}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARTE 4: COMPARACIÃ“N Y CONCLUSIONES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“Š MÃ‰TODOS CLÃSICOS vs LLMs\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "comparacion = \"\"\"\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ ASPECTO                 â”‚ MÃ‰TODOS CLÃSICOS     â”‚ LLMs                â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ Preprocesamiento        â”‚ Extensivo y manual   â”‚ MÃ­nimo o ninguno    â”‚\n",
        "â”‚ Features                â”‚ Manual (BoW, TF-IDF) â”‚ AutomÃ¡ticas         â”‚\n",
        "â”‚ Contexto                â”‚ Limitado             â”‚ Excelente           â”‚\n",
        "â”‚ SemÃ¡ntica               â”‚ BÃ¡sica               â”‚ Profunda            â”‚\n",
        "â”‚ Datos necesarios        â”‚ Miles por clase      â”‚ Zero/Few-shot       â”‚\n",
        "â”‚ Velocidad inferencia    â”‚ Muy rÃ¡pida           â”‚ MÃ¡s lenta           â”‚\n",
        "â”‚ Recursos computaciÃ³n    â”‚ Bajos                â”‚ Altos               â”‚\n",
        "â”‚ Tareas mÃºltiples        â”‚ Un modelo por tarea  â”‚ Modelo multiuso     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\"\"\"\n",
        "\n",
        "print(comparacion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BONUS: ClasificaciÃ³n Personalizada con Few-Shot\n",
        "\n",
        "**FEW-SHOT LEARNING**: Damos al LLM solo unos pocos ejemplos y aprende la tarea.\n",
        "Â¡No necesita reentrenamiento completo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ¯ BONUS: FEW-SHOT LEARNING\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Usamos un modelo mÃ¡s potente para few-shot\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "modelo_nombre = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_nombre)\n",
        "modelo = AutoModelForSequenceClassification.from_pretrained(\n",
        "    modelo_nombre,\n",
        "    num_labels=3\n",
        ")\n",
        "\n",
        "print(\"ğŸ’¡ Con few-shot, el modelo aprende de pocos ejemplos y generaliza.\")\n",
        "print(\"   Ãštil cuando tienes datos limitados o tareas muy especÃ­ficas.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CONCLUSIONES Y RECURSOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“ CONCLUSIONES\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ”— RECURSOS:\n",
        "   â€¢ HuggingFace Models: https://huggingface.co/models\n",
        "   â€¢ Transformers Library: https://huggingface.co/docs/transformers\n",
        "   â€¢ Papers With Code (NLP): https://paperswithcode.com/area/natural-language-processing\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nâœ¨ Â¡El futuro del NLP es emocionante! Sigue explorando... âœ¨\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
