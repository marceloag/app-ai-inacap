{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Procesamiento de Lenguaje Natural con LLMs\n",
        "### Modelo Cl√°sico a Modelos Modernos üöÄ\n",
        "\n",
        "Este notebook muestra la evoluci√≥n del NLP:\n",
        "1. Fundamentos cl√°sicos (preprocesamiento y representaci√≥n)\n",
        "2. Clasificaci√≥n tradicional\n",
        "3. LLMs modernos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARTE 1: FUNDAMENTOS CL√ÅSICOS DE NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install nltk transformers torch scikit-learn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "from collections import Counter\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset simple para clasificaci√≥n de sentimientos\n",
        "reviews = [\n",
        "    \"Me encanta este producto, es incre√≠ble!\",\n",
        "    \"P√©sima experiencia, no lo recomiendo\",\n",
        "    \"Es aceptable, cumple lo esperado\",\n",
        "    \"Excelente compra, super√≥ expectativas\",\n",
        "    \"Horrible servicio, muy decepcionado\"\n",
        "]\n",
        "sentimientos = ['positivo', 'negativo', 'neutral', 'positivo', 'negativo']\n",
        "\n",
        "print(\"=== DATASET ORIGINAL ===\")\n",
        "for i, (review, sent) in enumerate(zip(reviews, sentimientos), 1):\n",
        "    print(f\"{i}. [{sent}] {review}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocesamiento Cl√°sico\n",
        "\n",
        "**PREPROCESAMIENTO**: Limpiar y normalizar texto para an√°lisis.\n",
        "- Tokenizaci√≥n: dividir en palabras\n",
        "- Stop words: remover palabras comunes sin significado\n",
        "- Stemming: reducir palabras a su ra√≠z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "stemmer = SnowballStemmer('spanish')\n",
        "\n",
        "def preprocesar(texto):\n",
        "    # Limpiar y tokenizar\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto.lower())\n",
        "    tokens = word_tokenize(texto)\n",
        "    # Remover stop words y hacer stemming\n",
        "    tokens = [stemmer.stem(t) for t in tokens if t not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "reviews_procesados = [preprocesar(r) for r in reviews]\n",
        "\n",
        "print(\"\\n=== DESPU√âS DEL PREPROCESAMIENTO ===\")\n",
        "for i, review in enumerate(reviews_procesados, 1):\n",
        "    print(f\"{i}. {review}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Representaci√≥n: Bag of Words\n",
        "\n",
        "**BAG OF WORDS**: Representa texto como vector de frecuencias de palabras.\n",
        "Cada palabra del vocabulario es una dimensi√≥n.\n",
        "Problema: Pierde contexto y sem√°ntica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(reviews_procesados)\n",
        "\n",
        "print(\"\\n=== BAG OF WORDS (TF-IDF) ===\")\n",
        "print(f\"Vocabulario: {vectorizer.get_feature_names_out()}\")\n",
        "print(f\"Dimensi√≥n: {X.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clasificaci√≥n Tradicional\n",
        "\n",
        "**CLASIFICACI√ìN CL√ÅSICA**: Usamos algoritmos como Naive Bayes o SVM.\n",
        "Requieren mucho preprocesamiento y features engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "clf = MultinomialNB()\n",
        "scores = cross_val_score(clf, X, sentimientos, cv=2)\n",
        "print(f\"\\n=== CLASIFICACI√ìN TRADICIONAL (Naive Bayes) ===\")\n",
        "print(f\"Accuracy promedio: {scores.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARTE 2: ¬°LA REVOLUCI√ìN DE LOS LLMs! ü§ñ‚ú®\n",
        "\n",
        "**LLMs (Large Language Models)**: Modelos masivos entrenados en billones de palabras.\n",
        "- Entienden contexto, sem√°ntica y relaciones complejas\n",
        "- No necesitan preprocesamiento manual\n",
        "- Pueden hacer m√∫ltiples tareas sin reentrenamiento (zero-shot)\n",
        "- Ejemplos: BERT, GPT, LLaMA, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üöÄ CARGANDO MODELO DE LENGUAJE MODERNO...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Cargamos un modelo preentrenado en espa√±ol para an√°lisis de sentimientos\n",
        "# Este modelo ya fue entrenado en millones de textos\n",
        "clasificador_llm = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"pysentimiento/robertuito-sentiment-analysis\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Modelo cargado: RoBERTuito (BERT en espa√±ol)\")\n",
        "print(\"   Entrenado en millones de tweets en espa√±ol\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lisis con LLM - Zero Shot\n",
        "\n",
        "**ZERO-SHOT**: El modelo puede clasificar SIN ver ejemplos de entrenamiento.\n",
        "Ya aprendi√≥ sobre sentimientos de su entrenamiento masivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== CLASIFICACI√ìN CON LLM (Sin preprocesamiento) ===\\n\")\n",
        "\n",
        "for i, review in enumerate(reviews, 1):\n",
        "    resultado = clasificador_llm(review)[0]\n",
        "    etiqueta = resultado['label']\n",
        "    confianza = resultado['score']\n",
        "    \n",
        "    # Mapeo de etiquetas\n",
        "    etiqueta_es = {'POS': 'üòä Positivo', 'NEG': 'üòû Negativo', 'NEU': 'üòê Neutral'}\n",
        "    \n",
        "    print(f\"{i}. \\\"{review}\\\"\")\n",
        "    print(f\"   Predicci√≥n: {etiqueta_es.get(etiqueta, etiqueta)} (confianza: {confianza:.2%})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Casos m√°s complejos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üß™ PROBANDO CON CASOS DESAFIANTES\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "casos_complejos = [\n",
        "    \"No es que sea malo, pero definitivamente no es bueno\",  # Negaci√≥n compleja\n",
        "    \"Esperaba m√°s, aunque tiene sus puntos positivos\",       # Sentimiento mixto\n",
        "    \"¬°Qu√© desastre tan espectacular! (Es iron√≠a)\",          # Iron√≠a\n",
        "    \"Incre√≠ble c√≥mo algo tan caro puede ser tan mediocre\"   # Sarcasmo\n",
        "]\n",
        "\n",
        "for caso in casos_complejos:\n",
        "    resultado = clasificador_llm(caso)[0]\n",
        "    etiqueta = {'POS': 'üòä', 'NEG': 'üòû', 'NEU': 'üòê'}.get(resultado['label'], 'ü§î')\n",
        "    \n",
        "    print(f\"üìù \\\"{caso}\\\"\")\n",
        "    print(f\"   {etiqueta} {resultado['label']} ({resultado['score']:.1%})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARTE 3: GENERACI√ìN DE TEXTO CON LLMs üé®\n",
        "\n",
        "Los LLMs tambi√©n pueden **GENERAR** texto coherente.\n",
        "Vamos a usar un modelo generativo en espa√±ol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üé® GENERACI√ìN DE TEXTO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Modelo generativo (m√°s peque√±o para Google Colab)\n",
        "generador = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"DeepESP/gpt2-spanish\",\n",
        "    max_length=80\n",
        ")\n",
        "\n",
        "prompts = [\n",
        "    \"La inteligencia artificial es\",\n",
        "    \"En el futuro, los robots\",\n",
        "    \"El curso de IA me parece\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    texto_generado = generador(prompt, do_sample=True, temperature=0.7)[0]['generated_text']\n",
        "    print(f\"üí≠ Prompt: \\\"{prompt}\\\"\")\n",
        "    print(f\"‚ú® Generado: {texto_generado}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PARTE 4: COMPARACI√ìN Y CONCLUSIONES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä M√âTODOS CL√ÅSICOS vs LLMs\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "comparacion = \"\"\"\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ ASPECTO                 ‚îÇ M√âTODOS CL√ÅSICOS     ‚îÇ LLMs                ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ Preprocesamiento        ‚îÇ Extensivo y manual   ‚îÇ M√≠nimo o ninguno    ‚îÇ\n",
        "‚îÇ Features                ‚îÇ Manual (BoW, TF-IDF) ‚îÇ Autom√°ticas         ‚îÇ\n",
        "‚îÇ Contexto                ‚îÇ Limitado             ‚îÇ Excelente           ‚îÇ\n",
        "‚îÇ Sem√°ntica               ‚îÇ B√°sica               ‚îÇ Profunda            ‚îÇ\n",
        "‚îÇ Datos necesarios        ‚îÇ Miles por clase      ‚îÇ Zero/Few-shot       ‚îÇ\n",
        "‚îÇ Velocidad inferencia    ‚îÇ Muy r√°pida           ‚îÇ M√°s lenta           ‚îÇ\n",
        "‚îÇ Recursos computaci√≥n    ‚îÇ Bajos                ‚îÇ Altos               ‚îÇ\n",
        "‚îÇ Tareas m√∫ltiples        ‚îÇ Un modelo por tarea  ‚îÇ Modelo multiuso     ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\"\"\"\n",
        "\n",
        "print(comparacion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BONUS: Clasificaci√≥n Personalizada con Few-Shot\n",
        "\n",
        "**FEW-SHOT LEARNING**: Damos al LLM solo unos pocos ejemplos y aprende la tarea.\n",
        "¬°No necesita reentrenamiento completo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéØ BONUS: FEW-SHOT LEARNING\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Usamos un modelo m√°s potente para few-shot\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "modelo_nombre = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_nombre)\n",
        "modelo = AutoModelForSequenceClassification.from_pretrained(\n",
        "    modelo_nombre,\n",
        "    num_labels=3\n",
        ")\n",
        "\n",
        "print(\"üí° Con few-shot, el modelo aprende de pocos ejemplos y generaliza.\")\n",
        "print(\"   √ötil cuando tienes datos limitados o tareas muy espec√≠ficas.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CONCLUSIONES Y RECURSOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéì CONCLUSIONES\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"\"\"\n",
        "üîó RECURSOS:\n",
        "   ‚Ä¢ HuggingFace Models: https://huggingface.co/models\n",
        "   ‚Ä¢ Transformers Library: https://huggingface.co/docs/transformers\n",
        "   ‚Ä¢ Papers With Code (NLP): https://paperswithcode.com/area/natural-language-processing\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n‚ú® ¬°El futuro del NLP es emocionante! Sigue explorando... ‚ú®\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
